import os
import sys
import requests
import json
import time
from typing import Optional
# from dotenv import load_dotenv # <--- áƒ¬áƒáƒ¨áƒšáƒ˜áƒšáƒ˜áƒ!

# --- FastAPI áƒ“áƒ HTML áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ”áƒ‘áƒ˜ ---
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import uvicorn
from pypdf import PdfReader

# --- RAG áƒ˜áƒœáƒ¡áƒ¢áƒ áƒ£áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜ ---
try:
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    from langchain_openai import OpenAIEmbeddings 
    from langchain_community.vectorstores.chroma import Chroma
    from langchain_core.documents import Document
    RAG_TOOLS_AVAILABLE = True
except ImportError:
    RAG_TOOLS_AVAILABLE = False
    print("âŒ RAG áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ. RAG áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ.")
    
# --- áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ£áƒ áƒáƒªáƒ˜áƒ: áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒáƒ¢áƒáƒœáƒ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ”áƒ‘áƒ˜áƒ“áƒáƒœ ---
# áƒáƒ› áƒ”áƒ¢áƒáƒáƒ–áƒ” áƒ•áƒ”áƒ§áƒ áƒ“áƒœáƒáƒ‘áƒ˜áƒ— áƒ›áƒ®áƒáƒšáƒáƒ“ áƒ°áƒáƒ¡áƒ¢áƒ˜áƒœáƒ’ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ”áƒ‘áƒ¡ (Render)

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY") 
# (áƒáƒ¥ áƒáƒ áƒáƒ¤áƒ”áƒ áƒ˜ áƒ”áƒ¬áƒ”áƒ áƒ”áƒ‘áƒ load_dotenv-áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ˜áƒ—)

# --- áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒ RAG-áƒ˜áƒ¡ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜ ---
GEMINI_MODEL_NAME = "gemini-2.5-flash"
GPT_MODEL_NAME = "gpt-4o-mini" 
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL_NAME}:generateContent"
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

# --- RAG-áƒ˜áƒ¡ áƒ“áƒ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ£áƒ áƒáƒªáƒ˜áƒ ---
PERSONA_PDF_PATH = "prompt.pdf" 
CHROMA_PATH_GPT = "chroma_db_gpt"

# áƒ’áƒšáƒáƒ‘áƒáƒšáƒ£áƒ áƒ˜ áƒáƒ‘áƒ˜áƒ”áƒ¥áƒ¢áƒ”áƒ‘áƒ˜
global_rag_retriever_gemini: Optional[Chroma.as_retriever] = None
global_rag_retriever_gpt: Optional[Chroma.as_retriever] = None 

# --- áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ PDF-áƒ“áƒáƒœ áƒ©áƒáƒ¡áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒáƒ“ ---
def load_persona_from_pdf(file_path: str) -> str:
    """áƒ™áƒ˜áƒ—áƒ®áƒ£áƒšáƒáƒ‘áƒ¡ áƒ›áƒ—áƒ”áƒš áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¡ PDF áƒ¤áƒáƒ˜áƒšáƒ˜áƒ“áƒáƒœ pypdf-áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ˜áƒ—."""
    DEFAULT_PERSONA = "áƒ—áƒ¥áƒ•áƒ”áƒœ áƒ®áƒáƒ áƒ— áƒ¡áƒáƒ¡áƒáƒ áƒ’áƒ”áƒ‘áƒšáƒ áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒáƒáƒ¡áƒ£áƒ®áƒáƒ‘áƒ¡ áƒ¥áƒáƒ áƒ—áƒ£áƒš áƒ”áƒœáƒáƒ–áƒ”."
    try:
        reader = PdfReader(file_path)
        text = "".join(page.extract_text() + "\n\n" for page in reader.pages if page.extract_text())
        if not text.strip():
            print(f"âŒ ERROR: PDF áƒ¤áƒáƒ˜áƒšáƒ˜ '{file_path}' áƒªáƒáƒ áƒ˜áƒ”áƒšáƒ˜áƒ. áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ”áƒ¤áƒáƒšáƒ¢áƒ£áƒ áƒ˜ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ.")
            return DEFAULT_PERSONA
        print(f"âœ… áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ {file_path}-áƒ“áƒáƒœ.")
        return text.strip()
    except Exception as e:
        print(f"âŒ ERROR: áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ PDF-áƒ˜áƒ¡ áƒ¬áƒáƒ™áƒ˜áƒ—áƒ®áƒ•áƒ˜áƒ¡áƒáƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}. áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ”áƒ¤áƒáƒšáƒ¢áƒ£áƒ áƒ˜ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ.")
        return DEFAULT_PERSONA


CUSTOM_PERSONA_TEXT = load_persona_from_pdf(PERSONA_PDF_PATH)

# --- FastAPI áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ ---
app = FastAPI(title="Unified LLM Gateway (Gemini & GPT)", version="2.0")

# --- Startup áƒšáƒáƒ’áƒ˜áƒ™áƒ: RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ ---
@app.on_event("startup")
async def startup_event():
    global global_rag_retriever_gemini
    global global_rag_retriever_gpt
    
    if not RAG_TOOLS_AVAILABLE:
        print("RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒ’áƒáƒ›áƒáƒ¢áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ.")
        return
        
    # 2. ğŸ¤– GPT RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ 
    if OPENAI_API_KEY:
        os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
        if os.path.exists(CHROMA_PATH_GPT):
            try:
                embeddings_gpt = OpenAIEmbeddings(model="text-embedding-3-small")
                vector_store_gpt = Chroma(
                    persist_directory=CHROMA_PATH_GPT, 
                    embedding_function=embeddings_gpt
                )
                global_rag_retriever_gpt = vector_store_gpt.as_retriever(search_kwargs={"k": 3})
                print(f"âœ… GPT RAG Retriever áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ: {CHROMA_PATH_GPT}")
            except Exception as e:
                print(f"âŒ ERROR: GPT ChromaDB-áƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ: {e}.")
        else:
            print(f"âš ï¸ WARNING: áƒ•áƒ”áƒ¥áƒ¢áƒáƒ áƒ£áƒšáƒ˜ áƒ‘áƒáƒ–áƒ {CHROMA_PATH_GPT} áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ. GPT RAG áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ. áƒ’áƒáƒ£áƒ¨áƒ•áƒ˜áƒ— ingest_gpt.py")
    else:
        print("âŒ ERROR: OpenAI API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ.")


    # 1. ğŸ’ Gemini RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ (áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ GPT-áƒ˜áƒ¡ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒš áƒ‘áƒáƒ–áƒáƒ¡)
    if GEMINI_API_KEY and OPENAI_API_KEY:
        if global_rag_retriever_gpt:
            global_rag_retriever_gemini = global_rag_retriever_gpt
            print(f"âœ… Gemini RAG Retriever áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ“áƒáƒ§áƒ”áƒœáƒ“áƒ GPT-áƒ˜áƒ¡ áƒ‘áƒáƒ–áƒáƒ–áƒ”: {CHROMA_PATH_GPT}")
        elif os.path.exists(CHROMA_PATH_GPT): 
            try:
                embeddings_gpt = OpenAIEmbeddings(model="text-embedding-3-small") 
                vector_store = Chroma(
                    persist_directory=CHROMA_PATH_GPT, 
                    embedding_function=embeddings_gpt
                )
                global_rag_retriever_gemini = vector_store.as_retriever(search_kwargs={"k": 3})
            except Exception as e:
                print(f"âŒ ERROR: Gemini RAG áƒ•áƒ”áƒ  áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ GPT-áƒ˜áƒ¡ áƒ‘áƒáƒ–áƒ˜áƒ“áƒáƒœ: {e}. áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ.")
                global_rag_retriever_gemini = None 
        else:
            print(f"âš ï¸ WARNING: áƒ•áƒ”áƒ¥áƒ¢áƒáƒ áƒ£áƒšáƒ˜ áƒ‘áƒáƒ–áƒ {CHROMA_PATH_GPT} áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ. Gemini RAG áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ.")
    else:
        print("âŒ ERROR: Gemini áƒáƒœ OpenAI API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ.")


# --- CORS Middleware áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*", "http://localhost:8080"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- HTML áƒ¤áƒáƒ˜áƒšáƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ áƒ“áƒ áƒ¡áƒ”áƒ áƒ•áƒ˜áƒ áƒ”áƒ‘áƒ ---
try:
    with open("index.html", "r", encoding="utf-8") as f:
        HTML_CONTENT = f.read()
except FileNotFoundError:
    HTML_CONTENT = "<h1>FastAPI API áƒ›áƒ£áƒ¨áƒáƒáƒ‘áƒ¡, áƒ›áƒáƒ’áƒ áƒáƒ› áƒ¤áƒ áƒáƒœáƒ¢áƒ”áƒœáƒ“áƒ˜áƒ¡ (index.html) áƒ¤áƒáƒ˜áƒšáƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ.</h1>"

@app.get("/", response_class=HTMLResponse)
async def serve_frontend():
    return HTMLResponse(content=HTML_CONTENT, status_code=200)

# --- áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜ ---
class ChatbotRequest(BaseModel):
    prompt: str
    user_id: str
    model_choice: str = "gemini"

class ChatbotResponse(BaseModel):
    status: str
    processed_prompt: str
    ai_response: str
    result_data: dict

# --- 1. Gemini API-áƒ¡ áƒ’áƒáƒ›áƒáƒ«áƒáƒ®áƒ”áƒ‘áƒ (RAG áƒšáƒáƒ’áƒ˜áƒ™áƒ˜áƒ—) ---
def generate_gemini_content(prompt: str) -> str:
    if not GEMINI_API_KEY:
        return "ERROR: Gemini API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ."
        
    rag_context = ""
    is_rag_active = global_rag_retriever_gemini is not None
    
    if is_rag_active:
        try:
            docs: list[Document] = global_rag_retriever_gemini.get_relevant_documents(prompt)
            context_text = "\n---\n".join([doc.page_content for doc in docs])
            rag_context = (
                "áƒ—áƒ¥áƒ•áƒ”áƒœ áƒ›áƒáƒ’áƒ”áƒªáƒ”áƒ›áƒáƒ— áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ—áƒ˜ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ 'DOCUMENTS'-áƒ˜áƒ¡ áƒ¡áƒ”áƒ¥áƒªáƒ˜áƒáƒ¨áƒ˜. "
                "áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ— áƒ”áƒ¡ áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ, áƒ áƒáƒ› áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒáƒ— áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒáƒ¡.\n\n"
                f"--- DOCUMENTS ---\n{context_text}\n---"
            )
        except Exception:
            rag_context = "RAG retrieval failed."

    final_prompt = f"{rag_context}\n\náƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: {prompt}"

    headers = {"Content-Type": "application/json"}
    
    payload = {
        "contents": [
            {
                "role": "user",  
                "parts": [{"text": f"áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒ’áƒáƒœáƒ¡áƒáƒ–áƒ¦áƒ•áƒ áƒáƒ•áƒ¡ áƒ—áƒ¥áƒ•áƒ”áƒœáƒ¡ áƒ›áƒ—áƒáƒ•áƒáƒ  áƒáƒ”áƒ áƒ¡áƒáƒœáƒáƒ¡. áƒ›áƒ™áƒáƒªáƒ áƒáƒ“ áƒ›áƒ˜áƒ°áƒ§áƒ”áƒ•áƒ˜áƒ— áƒ›áƒáƒ¡:\n\n---\n{CUSTOM_PERSONA_TEXT}\n---"}]
            },
            {
                "role": "user",
                "parts": [{"text": final_prompt}]
            }
        ]
    }
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.post(
                f"{GEMINI_API_URL}?key={GEMINI_API_KEY}", 
                headers=headers, 
                data=json.dumps(payload),
                timeout=30 
            )
            
            if response.status_code >= 400:
                error_msg = f"Gemini API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ {response.status_code} áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ."
                try:
                    error_detail = response.json()
                    error_msg += f" áƒ“áƒ”áƒ¢áƒáƒšáƒ”áƒ‘áƒ˜: {error_detail.get('error', {}).get('message', 'áƒ“áƒ”áƒ¢áƒáƒšáƒ£áƒ áƒ˜ áƒ¨áƒ”áƒ¢áƒ§áƒáƒ‘áƒ˜áƒœáƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒ˜áƒ˜áƒ¦áƒ”áƒ¡.')}"
                except json.JSONDecodeError:
                    pass
                return f"ERROR: {error_msg}"

            response.raise_for_status() 
            result = response.json()
            
            candidate = result.get('candidates', [{}])[0]
            if candidate and candidate.get('content') and candidate['content'].get('parts'):
                return candidate['content']['parts'][0]['text']
            
            return f"Gemini API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ áƒáƒ áƒáƒ¡áƒ¢áƒáƒœáƒ“áƒáƒ áƒ¢áƒ£áƒšáƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜."

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                return f"ERROR: Gemini API-áƒ¡áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ. áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
        except Exception as e:
            return f"ERROR: áƒ›áƒáƒ£áƒšáƒáƒ“áƒœáƒ”áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
            
    return "ERROR: áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜."

# --- 2. GPT API-áƒ¡ áƒ’áƒáƒ›áƒáƒ«áƒáƒ®áƒ”áƒ‘áƒ (RAG áƒšáƒáƒ’áƒ˜áƒ™áƒ˜áƒ—) ---
def generate_gpt_content(prompt: str) -> str:
    if not OPENAI_API_KEY:
        return "ERROR: GPT API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ."
    
    rag_context = ""
    is_rag_active = global_rag_retriever_gpt is not None
    
    if is_rag_active:
        try:
            docs: list[Document] = global_rag_retriever_gpt.get_relevant_documents(prompt)
            context_text = "\n---\n".join([doc.page_content for doc in docs])
            
            rag_context = (
                f"áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ— áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡ áƒ’áƒáƒ¡áƒáƒªáƒ”áƒ›áƒáƒ“. áƒ—áƒ£ áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ›áƒáƒªáƒ”áƒ›áƒ£áƒš áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¨áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡, "
                f"áƒ›áƒáƒ¨áƒ˜áƒœ áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒ”áƒ— áƒ–áƒáƒ’áƒáƒ“áƒ˜ áƒªáƒáƒ“áƒœáƒ˜áƒ¡ áƒ¡áƒáƒ¤áƒ£áƒ«áƒ•áƒ”áƒšáƒ–áƒ”: \n\n--- DOCUMENTS ---\n{context_text}\n---"
            )
        except Exception as e:
            print(f"âŒ ERROR: GPT RAG Retrieval-áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}")
            rag_context = "RAG retrieval failed."

    final_user_prompt = f"{rag_context}\n\náƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: {prompt}"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}"
    }
    
    payload = {
        "model": GPT_MODEL_NAME,
        "messages": [
            {"role": "system", "content": f"{CUSTOM_PERSONA_TEXT}"},
            {"role": "user", "content": final_user_prompt}
        ]
    }
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.post(
                OPENAI_API_URL, 
                headers=headers, 
                data=json.dumps(payload),
                timeout=30 
            )
            
            if response.status_code >= 400:
                error_msg = f"OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ {response.status_code} áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ."
                try:
                    error_detail = response.json()
                    error_msg += f" áƒ“áƒ”áƒ¢áƒáƒšáƒ”áƒ‘áƒ˜: {error_detail.get('error', {}).get('message', 'áƒ“áƒ”áƒ¢áƒáƒšáƒ£áƒ áƒ˜ áƒ¨áƒ”áƒ¢áƒ§áƒáƒ‘áƒ˜áƒœáƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒ˜áƒ˜áƒ¦áƒ”áƒ¡.')}"
                except json.JSONDecodeError:
                    pass
                return f"ERROR: {error_msg}"

            response.raise_for_status() 
            result = response.json()
            
            if result.get('choices'):
                return result['choices'][0]['message']['content']
            
            return f"OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ áƒáƒ áƒáƒ¡áƒ¢áƒáƒœáƒ“áƒáƒ áƒ¢áƒ£áƒšáƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜."

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                return f"ERROR: OpenAI API-áƒ¡áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ. áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
        except Exception as e:
            return f"ERROR: áƒ›áƒáƒ£áƒšáƒáƒ“áƒœáƒ”áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
            
    return "ERROR: áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜."


# --- API áƒ”áƒœáƒ“áƒáƒáƒ˜áƒœáƒ¢áƒ”áƒ‘áƒ˜ ---
@app.get("/status")
def read_root():
    rag_gemini_status = "áƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ" if global_rag_retriever_gemini else "áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ (áƒ‘áƒáƒ–áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ)"
    rag_gpt_status = "áƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ" if global_rag_retriever_gpt else "áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ (áƒ’áƒáƒ£áƒ¨áƒ•áƒ˜áƒ— ingest_gpt.py)"
    
    return {
        "message": "API áƒ›áƒ£áƒ¨áƒáƒáƒ‘áƒ¡!", 
        "Gemini_Model": GEMINI_MODEL_NAME,
        "GPT_Model": GPT_MODEL_NAME,
        "RAG_Status_Gemini": rag_gemini_status,
        "RAG_Status_GPT": rag_gpt_status,
        "Note": "áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ— /process_query áƒ”áƒœáƒ“áƒ¤áƒáƒ˜áƒœáƒ—áƒ˜, model_choice: 'gemini' áƒáƒœ 'gpt'"
    }

@app.post("/process_query", response_model=ChatbotResponse)
async def process_query(
    request_data: ChatbotRequest
):
    model_choice = request_data.model_choice.lower()
    
    if model_choice == "gemini":
        ai_response = generate_gemini_content(request_data.prompt)
        used_model_name = GEMINI_MODEL_NAME
        is_rag_active = global_rag_retriever_gemini is not None
    elif model_choice == "gpt":
        ai_response = generate_gpt_content(request_data.prompt)
        used_model_name = GPT_MODEL_NAME
        is_rag_active = global_rag_retriever_gpt is not None
    else:
        ai_response = generate_gemini_content(request_data.prompt)
        used_model_name = GEMINI_MODEL_NAME
        is_rag_active = global_rag_retriever_gemini is not None
        
    response_data = {
        "user": request_data.user_id,
        "length": len(request_data.prompt),
        "is_rag_active": is_rag_active,
        "used_model": used_model_name
    }
    
    return ChatbotResponse(
        status="success",
        processed_prompt=f"áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ áƒ›áƒáƒ—áƒ®áƒáƒ•áƒœáƒ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ {used_model_name}-áƒ˜áƒ¡ áƒ›áƒ˜áƒ”áƒ .",
        ai_response=ai_response,
        result_data=response_data,
    )

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT", 8090)))
